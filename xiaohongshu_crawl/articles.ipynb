{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请扫码登录\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "采集输出-小红书笔记详情-2025-02-19.xlsx 开始写入文件，切勿关闭进程。\n",
      "采集输出-小红书笔记详情-2025-02-19.xlsx 写入文件结束。\n",
      "数据采集完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from DrissionPage import ChromiumPage\n",
    "from DataRecorder import Recorder\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "\n",
    "def sign_in():\n",
    "    \"\"\"\n",
    "    首次运行需要登录小红书\n",
    "    \"\"\"\n",
    "    sign_in_page = ChromiumPage()\n",
    "    sign_in_page.get('https://www.xiaohongshu.com')\n",
    "    print(\"请扫码登录\")\n",
    "    time.sleep(20)\n",
    "\n",
    "def read_urls_from_txt(path):\n",
    "    \"\"\"\n",
    "    从txt文件中读取所有笔记链接\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as file:\n",
    "        urls = [line.strip() for line in file.readlines()]\n",
    "    return urls\n",
    "\n",
    "def open_url(url):\n",
    "    \"\"\"\n",
    "    打开小红书笔记详情页\n",
    "    \"\"\"\n",
    "    global page\n",
    "    page = ChromiumPage()\n",
    "    page.get(f'{url}')\n",
    "    time.sleep(3)  # 等待页面加载\n",
    "    return page\n",
    "\n",
    "def get_meta_content(page, meta_name):\n",
    "    \"\"\"\n",
    "    获取指定meta标签的内容\n",
    "    \"\"\"\n",
    "    try:\n",
    "        meta = page.ele(f'xpath://meta[@name=\"{meta_name}\"]', timeout=5)\n",
    "        return meta.attr('content') if meta else ''\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def get_note_info(page):\n",
    "    \"\"\"\n",
    "    从meta标签获取笔记信息\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 获取标题\n",
    "        title = get_meta_content(page, 'og:title')\n",
    "        if title:\n",
    "            title = title.replace(' - 小红书', '')  # 移除后缀\n",
    "            \n",
    "        # 获取描述（笔记内容）\n",
    "        content = get_meta_content(page, 'description')\n",
    "        \n",
    "        # 获取链接\n",
    "        note_link = get_meta_content(page, 'og:url')\n",
    "        \n",
    "        # 获取标签（关键词）\n",
    "        keywords = get_meta_content(page, 'keywords')\n",
    "        tags = keywords.split(', ') if keywords else []\n",
    "        \n",
    "        # 获取统计数据\n",
    "        like_count = get_meta_content(page, 'og:xhs:note_like')\n",
    "        collect_count = get_meta_content(page, 'og:xhs:note_collect')\n",
    "        comment_count = get_meta_content(page, 'og:xhs:note_comment')\n",
    "        \n",
    "        info = {\n",
    "            'title': title,\n",
    "            'content': content,\n",
    "            'note_link': note_link,\n",
    "            'tags': ','.join(tags),\n",
    "            'like_count': like_count,\n",
    "            'collect_count': collect_count,\n",
    "            'comment_count': comment_count\n",
    "        }\n",
    "        return info\n",
    "    except Exception as e:\n",
    "        print(f\"获取笔记信息失败: {str(e)}\")\n",
    "        return {\n",
    "            'title': '',\n",
    "            'content': '',\n",
    "            'note_link': '',\n",
    "            'tags': '',\n",
    "            'like_count': '0',\n",
    "            'collect_count': '0',\n",
    "            'comment_count': '0'\n",
    "        }\n",
    "\n",
    "def get_note_page_info(url):\n",
    "    \"\"\"\n",
    "    获取笔记页面所有信息\n",
    "    \"\"\"\n",
    "    # 访问url\n",
    "    page = open_url(url)\n",
    "    \n",
    "    # 获取笔记信息\n",
    "    note_info = get_note_info(page)\n",
    "    \n",
    "    return note_info\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # 第1次运行需要登录，后面不用登录，可以注释掉\n",
    "        sign_in()\n",
    "\n",
    "        # 获取当前日期\n",
    "        current_date = date.today()\n",
    "        \n",
    "        # 创建输出文件名\n",
    "        output_file = f'采集输出-小红书笔记详情-{current_date}.xlsx'\n",
    "\n",
    "        # 新建一个excel表格，用来保存数据\n",
    "        r = Recorder(path=output_file, cache_size=20)\n",
    "\n",
    "        # 设置要采集的笔记链接\n",
    "        note_urls_file_path = '需要采集的笔记链接（每行放1个链接）.txt'\n",
    "\n",
    "        # 从txt文件读取urls\n",
    "        note_urls = read_urls_from_txt(note_urls_file_path)\n",
    "\n",
    "        for note_url in tqdm(note_urls):\n",
    "            try:\n",
    "                # 采集笔记详情\n",
    "                note_info = get_note_page_info(note_url)\n",
    "                \n",
    "                # 整理数据格式\n",
    "                new_note_contents_dict = {\n",
    "                    '采集日期': str(current_date),\n",
    "                    '作者': '',  # 暂时无法从meta标签获取作者信息\n",
    "                    '笔记标题': note_info['title'],\n",
    "                    '发布日期': '',  # 暂时无法从meta标签获取发布日期\n",
    "                    'IP属地': '',  # 暂时无法从meta标签获取IP属地\n",
    "                    '点赞数': note_info['like_count'],\n",
    "                    '收藏数': note_info['collect_count'],\n",
    "                    '评论数': note_info['comment_count'],\n",
    "                    # '笔记链接': note_info['note_link'],\n",
    "                    '笔记链接': note_url,\n",
    "                    '作者链接': '',  # 暂时无法从meta标签获取作者链接\n",
    "                    '标签': note_info['tags'],\n",
    "                    '笔记内容': note_info['content']\n",
    "                }\n",
    "                \n",
    "                # 数据写入缓存\n",
    "                r.add_data(new_note_contents_dict)\n",
    "                \n",
    "                # 避免频繁请求\n",
    "                time.sleep(3)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"处理笔记 {note_url} 时出错: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # 保存excel文件\n",
    "        r.record()\n",
    "        print(\"数据采集完成！\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"程序执行出错: {str(e)}\")\n",
    "        # 确保数据被保存\n",
    "        try:\n",
    "            r.record()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
